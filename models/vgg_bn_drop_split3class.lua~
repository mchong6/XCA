require 'nn'

local MaxPooling = nn.SpatialMaxPooling

local main = nn.Sequential()

-- building block
local function ConvBNReLU2(nInputPlane, nOutputPlane)
  main:add(nn.SpatialConvolution(nInputPlane, nOutputPlane, 3,3, 1,1, 1,1))
  main:add(nn.SpatialBatchNormalization(nOutputPlane,1e-3))
  main:add(nn.ReLU(true))
  return main
end
ConvBNReLU2(3,64):add(nn.Dropout(0.3))
ConvBNReLU2(64,64)
main:add(MaxPooling(2,2,2,2):ceil())


local vgg = nn.Sequential()

-- building block
local function ConvBNReLU(nInputPlane, nOutputPlane)
  vgg:add(nn.SpatialConvolution(nInputPlane, nOutputPlane, 3,3, 1,1, 1,1))
  vgg:add(nn.SpatialBatchNormalization(nOutputPlane,1e-3))
  vgg:add(nn.ReLU(true))
  return vgg
end
ConvBNReLU(64,128):add(nn.Dropout(0.4))
ConvBNReLU(128,128)
vgg:add(MaxPooling(2,2,2,2):ceil())

ConvBNReLU(128,256):add(nn.Dropout(0.4))
ConvBNReLU(256,256):add(nn.Dropout(0.4))
ConvBNReLU(256,256)
vgg:add(MaxPooling(2,2,2,2):ceil())

ConvBNReLU(256,512):add(nn.Dropout(0.4))
ConvBNReLU(512,512):add(nn.Dropout(0.4))
ConvBNReLU(512,512)
vgg:add(MaxPooling(2,2,2,2):ceil())


ConvBNReLU(512,512):add(nn.Dropout(0.4))
ConvBNReLU(512,512):add(nn.Dropout(0.4))
ConvBNReLU(512,512)
vgg:add(MaxPooling(2,2,2,2):ceil())
vgg:add(nn.View(512))

local vgg2 = vgg:clone()
local vgg3 = vgg:clone()
local vgg4 = vgg:clone()
local concat = nn.Concat(2)

classifier = nn.Sequential()
classifier:add(nn.Dropout(0.5))
classifier:add(nn.Linear(512,256))
classifier:add(nn.BatchNormalization(256))
classifier:add(nn.ReLU(true))
classifier:add(nn.Dropout(0.5))
classifier:add(nn.Linear(256,32))
classifier:add(nn.BatchNormalization(32))
classifier:add(nn.ReLU(true))
classifier:add(nn.Dropout(0.5))
classifier:add(nn.Linear(32,1))
classifier:add(nn.Sigmoid())
vgg:add(classifier)

classifier3 = classifier:clone()
classifier4 = classifier3:clone('weight','bias','gradWeight','gradBias')
classifier5 = classifier3:clone('weight','bias','gradWeight','gradBias')
classifier7 = classifier3:clone('weight','bias','gradWeight','gradBias')
classifier2 = classifier:clone('weight','bias','gradWeight','gradBias')
classifier6 = classifier:clone('weight','bias','gradWeight','gradBias')

local concatvgg = nn.Concat(2)
concatvgg:add(classifier)
concatvgg:add(classifier4)
vgg:add(concatvgg)

local concatvgg2 = nn.Concat(2)
concatvgg2:add(classifier2)
concatvgg2:add(classifier5)
vgg2:add(concatvgg2)

local concatvgg3 = nn.Concat(2)
concatvgg3:add(classifier6)
concatvgg3:add(classifier7)
vgg4:add(concatvgg3)

vgg3:add(classifier3)	

concat:add(vgg)
concat:add(vgg2)
concat:add(vgg4)
concat:add(vgg3)
main:add(concat)


-- initialization from MSR
local function MSRinit(net)
  local function init(name)
    for k,v in pairs(net:findModules(name)) do
      local n = v.kW*v.kH*v.nOutputPlane
      v.weight:normal(0,math.sqrt(2/n))
      v.bias:zero()
    end
  end
  -- have to do for both backends
  init'nn.SpatialConvolution'
end

MSRinit(vgg)

-- check that we can propagate forward without errors
-- should get 16x10 tensor
--print(#main:cuda():forward(torch.CudaTensor(100,3,32,32)))

return main:cuda()
